"""
AI åˆ†æå¼•æ“æ¨¡å—
ä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼å¤§æ¨¡å‹è¿›è¡Œçƒ­ç‚¹åˆ†æå’Œè¯é¢˜ç”Ÿæˆ
é‡‡ç”¨ dashscope.Generation APIï¼ˆæ¨èæ–¹å¼ï¼‰

åŠŸèƒ½ï¼š
- çˆ†æ¬¾ç¬”è®°è¶‹åŠ¿åˆ†æ
- è¯é¢˜ç”Ÿæˆï¼ˆæ¯è¯é¢˜ç»Ÿä¸€è§†è§‰é£æ ¼ + å¤šå¼ å…³è”å›¾ç‰‡ï¼‰
- å›¾ç‰‡æç¤ºè¯ä¼˜åŒ–
- å†…ç½®æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
"""

import os
import json
import traceback
from dashscope import Generation
import dashscope
from typing import List, Dict, Optional, Callable, Any
from datetime import datetime

from utils.retry import call_with_retry

# é…ç½® dashscope åŸºç¡€ URL
dashscope.base_http_api_url = "https://dashscope.aliyuncs.com/api/v1"


class AIEngine:
    """AI åˆ†æå¼•æ“ - OpenAI å…¼å®¹æ¥å£"""

    # å°çº¢ä¹¦é£æ ¼æç¤ºè¯æ¨¡æ¿
    XHS_STYLE_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°çº¢ä¹¦çˆ†æ¬¾å†…å®¹ç­–åˆ’ä¸“å®¶ï¼Œæ·±è°™å¹³å°ç®—æ³•å’Œç”¨æˆ·å¿ƒç†ã€‚
ä½ æ“…é•¿åˆ†æçˆ†æ¬¾å†…å®¹çš„åº•å±‚é€»è¾‘ï¼Œå¹¶èƒ½åˆ›é€ å‡ºå…·æœ‰ç—…æ¯’ä¼ æ’­æ½œåŠ›çš„æ–°å†…å®¹ã€‚

## é‡è¦åŸåˆ™ï¼šåŸºäºäº‹å®ï¼Œæ‹’ç»å¹»è§‰

ä½ å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹åŸåˆ™ï¼š
1. **åªåŸºäºæä¾›çš„åŸå§‹æ•°æ®è¿›è¡Œåˆ†æå’Œåˆ›ä½œ**ï¼Œä¸è¦ç¼–é€ æ•°æ®ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯
2. **ä¸è¦å‡­ç©ºæé€ å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚ã€æ•°æ®ã€å¯¹æ¯”ç»“æœ**
3. **æ¯ä¸ªè§‚ç‚¹éƒ½å¿…é¡»èƒ½åœ¨åŸå§‹ç¬”è®°ä¸­æ‰¾åˆ°ä¾æ®**
4. å¦‚æœåŸå§‹æ•°æ®ä¸è¶³ä»¥æ”¯æ’‘æŸä¸ªè¯é¢˜ï¼Œå°±ä¸è¦ç”Ÿæˆè¯¥è¯é¢˜
5. å®å¯è¯é¢˜å°‘ä¸€äº›ï¼Œä¹Ÿä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å†…å®¹"""

    def __init__(
        self,
        api_key: str,
        model: str = "qwen3-max-2026-01-23",
        enable_thinking: Optional[bool] = None,
        max_retries: int = 3,
    ):
        """
        åˆå§‹åŒ– AI å¼•æ“

        Args:
            api_key: é˜¿é‡Œäº‘ç™¾ç‚¼ API Key
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œé»˜è®¤ qwen3-max-2026-01-23
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆNone=è‡ªåŠ¨, True=å¼ºåˆ¶å¯ç”¨, False=å¼ºåˆ¶ç¦ç”¨ï¼‰
            max_retries: API è°ƒç”¨æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.api_key = api_key
        self.model = model
        self.base_url = (
            "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
        )
        self.enable_thinking = enable_thinking
        self.max_retries = max_retries

        # æ ¹æ®æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼è®¾ç½®è¶…æ—¶æ—¶é—´
        self.timeout = 600 if enable_thinking else 120

    def validate_api_key(self, log_callback: Optional[Callable] = None) -> bool:
        """
        éªŒè¯ API Key æ˜¯å¦æœ‰æ•ˆ

        Args:
            log_callback: æ—¥å¿—å›è°ƒ

        Returns:
            æ˜¯å¦éªŒè¯é€šè¿‡
        """
        if log_callback is None:
            log_callback = print

        try:
            log_callback("ğŸ” æ­£åœ¨éªŒè¯ API Key...")

            test_messages = [{"role": "user", "content": "Hello"}]

            response = Generation.call(
                api_key=self.api_key,
                model=self.model,
                messages=test_messages,
                result_format="message",
                max_tokens=10,
            )

            if response.status_code == 200:
                log_callback("âœ… API Key éªŒè¯é€šè¿‡")
                return True
            else:
                error_code = getattr(response, "code", "unknown")
                error_msg = getattr(response, "message", "æœªçŸ¥é”™è¯¯")
                log_callback("âŒ API Key éªŒè¯å¤±è´¥")
                log_callback(f"   çŠ¶æ€ç : {response.status_code}")
                log_callback(f"   é”™è¯¯ç : {error_code}")
                log_callback(f"   é”™è¯¯ä¿¡æ¯: {error_msg}")

                if response.status_code == 401:
                    log_callback("ğŸ’¡ æç¤º: API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ")
                elif response.status_code == 403:
                    log_callback(f"ğŸ’¡ æç¤º: æ²¡æœ‰æƒé™è®¿é—®æ¨¡å‹ '{self.model}'")
                    log_callback("   è¯·æ£€æŸ¥: 1) è´¦æˆ·æ˜¯å¦å·²å®Œæˆå®åè®¤è¯")
                    log_callback("          2) æ˜¯å¦å·²å¼€é€šç™¾ç‚¼æœåŠ¡")
                    log_callback("          3) æ˜¯å¦æœ‰è¯¥æ¨¡å‹çš„è®¿é—®æƒé™")

                return False

        except Exception as e:
            log_callback(f"âŒ API Key éªŒè¯å‡ºé”™: {e}")
            return False

    def _call_api_once(
        self,
        messages: List[Dict],
        temperature: float = 0.7,
        enable_thinking: Optional[bool] = None,
        log_callback: Optional[Callable] = None,
    ) -> str:
        """
        å•æ¬¡ API è°ƒç”¨ï¼ˆä¸å«é‡è¯•ï¼Œç”± _call_api åŒ…è£…é‡è¯•é€»è¾‘ï¼‰

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
            log_callback: æ—¥å¿—å›è°ƒ

        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬

        Raises:
            Exception: API è°ƒç”¨å¤±è´¥
        """
        if log_callback is None:
            log_callback = print

        if enable_thinking is None:
            enable_thinking = self.enable_thinking

        log_callback("")
        log_callback("ğŸŒ è°ƒç”¨ API...")
        log_callback(f"   æ¨¡å‹: {self.model} | æ¸©åº¦: {temperature}")
        if enable_thinking and "qwen3" in self.model.lower():
            log_callback("   ğŸ’­ æ€è€ƒæ¨¡å¼å·²å¯ç”¨")

        start_time = datetime.now()

        # æ„å»º API è°ƒç”¨å‚æ•°
        call_params = {
            "api_key": self.api_key,
            "model": self.model,
            "messages": messages,
            "result_format": "message",
            "temperature": temperature,
            "request_timeout": self.timeout,  # dashscope SDK ä½¿ç”¨ request_timeout
        }

        if enable_thinking and "qwen3" in self.model.lower():
            call_params["enable_thinking"] = True

        # è°ƒç”¨ API
        response: Any = Generation.call(**call_params)

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # æ£€æŸ¥å“åº”çŠ¶æ€ç 
        if response.status_code != 200:
            error_msg = f"HTTP {response.status_code}"
            if hasattr(response, "message") and response.message:
                error_msg = f"{error_msg} - {response.message}"
            elif hasattr(response, "code") and response.code:
                error_msg = f"{error_msg} - é”™è¯¯ç : {response.code}"

            log_callback(f"   âŒ API è¿”å›é 200 çŠ¶æ€ç ")
            log_callback(f"      çŠ¶æ€ç : {response.status_code}")
            if hasattr(response, "code"):
                log_callback(f"      é”™è¯¯ç : {response.code}")
            if hasattr(response, "message") and response.message:
                log_callback(f"      é”™è¯¯ä¿¡æ¯: {response.message}")

            try:
                if hasattr(response, "output") and response.output:
                    log_callback(f"      è¾“å‡ºå†…å®¹: {response.output}")
            except Exception:
                pass

            if response.status_code == 401:
                raise Exception("API Key æ— æ•ˆæˆ–å·²è¿‡æœŸã€‚è¯·æ£€æŸ¥é…ç½®ã€‚")
            elif response.status_code == 403:
                raise Exception(
                    f"æ²¡æœ‰æƒé™è®¿é—®è¯¥æ¨¡å‹ '{self.model}'ã€‚"
                    "è¯·æ£€æŸ¥ API Keyã€æ¨¡å‹æƒé™ã€å®åè®¤è¯ã€‚"
                )
            elif response.status_code == 429:
                raise Exception("è§¦å‘é€Ÿç‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            elif response.status_code == 400:
                raise Exception(f"è¯·æ±‚å‚æ•°é”™è¯¯: {error_msg}")
            else:
                raise Exception(f"API è¯·æ±‚å¤±è´¥: {error_msg}")

        # è§£æå“åº”
        if (
            hasattr(response, "code")
            and response.code
            and str(response.code) not in ["200", "None", "", "0"]
        ):
            error_msg = (
                response.message
                if hasattr(response, "message") and response.message
                else f"é”™è¯¯ç : {response.code}"
            )
            raise Exception(f"API è¿”å›é”™è¯¯: {error_msg}")

        if not hasattr(response, "output") or not response.output:
            raise Exception("API è¿”å›ç©ºç»“æœï¼ˆæ—  output å­—æ®µï¼‰")

        if (
            not hasattr(response.output, "choices")
            or not response.output.choices
        ):
            raise Exception("API è¿”å›ç©ºç»“æœï¼ˆæ—  choices å­—æ®µï¼‰")

        message = response.output.choices[0].message
        response_content = (
            str(message.content) if hasattr(message, "content") else ""
        )

        content_length = len(response_content) if response_content else 0
        log_callback(f"   âœ… æˆåŠŸ ({duration:.1f}s, {content_length} å­—ç¬¦)")

        if enable_thinking and hasattr(message, "reasoning_content"):
            reasoning = message.reasoning_content
            if reasoning:
                log_callback("   ğŸ’­ æ€è€ƒè¿‡ç¨‹å·²ç”Ÿæˆ")

        if not response_content:
            log_callback("   âš ï¸  è­¦å‘Š: API è¿”å›ç©ºå†…å®¹")

        return response_content

    def _call_api(
        self,
        messages: List[Dict],
        temperature: float = 0.7,
        enable_thinking: Optional[bool] = None,
        log_callback: Optional[Callable] = None,
    ) -> str:
        """
        è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼ APIï¼ˆå¸¦è‡ªåŠ¨é‡è¯•ï¼‰

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
            log_callback: æ—¥å¿—å›è°ƒ

        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        if log_callback is None:
            log_callback = print

        return call_with_retry(
            self._call_api_once,
            messages,
            temperature,
            enable_thinking,
            log_callback,
            max_retries=self.max_retries,
            base_delay=3.0,
            max_delay=60.0,
            backoff_factor=2.0,
            log_callback=log_callback,
        )

    def analyze_trends(
        self,
        notes: List[Dict],
        top_n: int = 50,
        log_callback: Optional[Callable] = None,
    ) -> Dict:
        """
        åˆ†æçƒ­é—¨è¶‹åŠ¿

        Args:
            notes: ç¬”è®°åˆ—è¡¨
            top_n: åˆ†æå‰ N æ¡
            log_callback: æ—¥å¿—å›è°ƒ

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if log_callback is None:
            log_callback = print

        log_callback(f"\n{'-' * 70}")
        log_callback("ğŸ§  åˆ†æçƒ­ç‚¹è¶‹åŠ¿")
        log_callback(f"{'-' * 70}")

        # é™åˆ¶ä¼ å…¥LLMçš„ç¬”è®°æ•°é‡ï¼Œé¿å…promptè¿‡å¤§å¯¼è‡´è¶…æ—¶
        # ç¬”è®°å·²æŒ‰è´¨é‡æ’åºï¼Œå–å‰30æ¡è¶³å¤Ÿåˆ†æè¶‹åŠ¿
        max_analyze = min(top_n, len(notes), 30)
        log_callback(f"ğŸ“Š åˆ†æç¬”è®°æ•°: {max_analyze} æ¡ï¼ˆå…±æœé›† {len(notes)} æ¡ï¼‰\n")

        # å‡†å¤‡åˆ†ææ•°æ®ï¼ˆä¿ç•™æ›´å¤šåŸå§‹ä¿¡æ¯ç”¨äºäº‹å®æº¯æºï¼‰
        analyze_data = []
        for idx, note in enumerate(notes[:max_analyze]):
            analyze_data.append(
                {
                    "index": idx + 1,
                    "note_id": note.get("note_id", ""),
                    "title": note.get("title", ""),
                    "desc": note.get("desc", "")[:300],
                    "liked_count": note.get("liked_count", 0),
                    "collected_count": note.get("collected_count", 0),
                    "comment_count": note.get("comment_count", 0),
                    "share_count": note.get("share_count", 0),
                    "tags": note.get("tags", [])[:5],
                    "user_nickname": note.get("user", {}).get("nickname", ""),
                }
            )

        system_message = {"role": "system", "content": self.XHS_STYLE_PROMPT}

        user_message = {
            "role": "user",
            "content": f"""è¯·åŸºäºä»¥ä¸‹å°çº¢ä¹¦çœŸå®ç¬”è®°æ•°æ®è¿›è¡Œåˆ†æã€‚

æ³¨æ„ï¼šåªåˆ†ææ•°æ®ä¸­å®é™…å­˜åœ¨çš„å†…å®¹ï¼Œä¸è¦ç¼–é€ æˆ–æ¨æµ‹æ•°æ®ä¸­æ²¡æœ‰çš„ä¿¡æ¯ã€‚
å¦‚æœæŸä¸ªç¬”è®°çš„æè¿°(desc)ä¸ºç©ºï¼Œåªèƒ½ä»æ ‡é¢˜æ¨æ–­å¤§æ–¹å‘ï¼Œä¸è¦è„‘è¡¥å…·ä½“å†…å®¹ã€‚

åŸå§‹ç¬”è®°æ•°æ®ï¼š
{json.dumps(analyze_data, ensure_ascii=False, indent=2)}

è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æï¼š

1. **é«˜é¢‘å…³é”®è¯**ï¼ˆæ ‡é¢˜å’Œæè¿°ä¸­å®é™…å‡ºç°3æ¬¡ä»¥ä¸Šçš„è¯ï¼‰
2. **æƒ…ç»ªä»·å€¼ç‚¹**ï¼ˆä»æ ‡é¢˜å¯ä»¥åˆ¤æ–­çš„æƒ…ç»ªè§¦å‘ç±»å‹ï¼‰
3. **çˆ†æ¬¾æ ‡é¢˜æ¨¡å¼**ï¼ˆå¼•ç”¨å…·ä½“çš„æ ‡é¢˜ä½œä¸ºä¾‹å­ï¼‰
4. **å†…å®¹ç±»å‹åˆ†å¸ƒ**ï¼ˆæ•™ç¨‹ç±»/èµ„è®¯ç±»/è¯„æµ‹ç±»/ç»éªŒåˆ†äº«ç±»ç­‰ï¼Œç»Ÿè®¡å„ç±»å æ¯”ï¼‰
5. **äº’åŠ¨æ•°æ®æ´å¯Ÿ**ï¼ˆå“ªç±»æ ‡é¢˜è·å¾—æœ€é«˜ç‚¹èµ/æ”¶è—/åˆ†äº«ï¼‰
6. **ä»£è¡¨æ€§ç¬”è®°**ï¼ˆåˆ—å‡ºäº’åŠ¨é‡æœ€é«˜çš„5æ¡ç¬”è®°æ ‡é¢˜å’Œæ•°æ®ï¼‰

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
{{
  "top_keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...],
  "emotion_points": ["æƒ…ç»ªç‚¹1", "æƒ…ç»ªç‚¹2", ...],
  "title_patterns": [
    {{"pattern": "æ¨¡å¼åç§°", "example": "å®é™…æ ‡é¢˜åŸæ–‡", "count": å‡ºç°æ¬¡æ•°}}
  ],
  "content_types": [
    {{"type": "ç±»å‹å", "count": æ•°é‡, "examples": ["æ ‡é¢˜1", "æ ‡é¢˜2"]}}
  ],
  "top_notes": [
    {{"title": "æ ‡é¢˜", "liked": ç‚¹èµæ•°, "collected": æ”¶è—æ•°, "note_id": "ID"}}
  ],
  "interaction_insight": "äº’åŠ¨æ•°æ®æ´å¯Ÿ...",
  "viral_logic": "çˆ†æ¬¾åº•å±‚é€»è¾‘æ€»ç»“"
}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚""",
        }

        try:
            task_enable_thinking = (
                self.enable_thinking if self.enable_thinking is not None else True
            )
            response_text = self._call_api(
                [system_message, user_message],
                temperature=0.3,
                enable_thinking=task_enable_thinking,
                log_callback=log_callback,
            )

            response_text = (
                response_text.replace("```json", "").replace("```", "").strip()
            )

            analyze_result = json.loads(response_text)
            log_callback("âœ… åˆ†æå®Œæˆ\n")

            return analyze_result

        except Exception as e:
            log_callback(f"âŒ åˆ†æå¤±è´¥: {e}")
            raise

    def generate_topics(
        self,
        analyze_result: Dict,
        keyword: str,
        top_n: int = 10,
        images_per_topic: int = 5,
        log_callback: Optional[Callable] = None,
    ) -> List[Dict]:
        """
        ç”Ÿæˆæ–°è¯é¢˜ï¼Œæ¯ä¸ªè¯é¢˜åŒ…å«ç»Ÿä¸€è§†è§‰é£æ ¼ + å¤šå¼ å…³è”å›¾ç‰‡æç¤ºè¯

        æ ¸å¿ƒç­–ç•¥ï¼š
        - æ¯ä¸ªè¯é¢˜é€‰æ‹©ä¸€ç§ç»Ÿä¸€çš„è§†è§‰é£æ ¼
        - åŒä¸€è¯é¢˜çš„ N å¼ å›¾ç‰‡é£æ ¼ä¸€è‡´ã€å†…å®¹ä¸åŒ
        - N å¼ å›¾ç‰‡æ„æˆè§†è§‰å™äº‹ï¼ˆè½®æ’­å›¾æ•…äº‹çº¿ï¼‰
        - ä¸åŒè¯é¢˜ä¹‹é—´ä½¿ç”¨ä¸åŒçš„è§†è§‰é£æ ¼

        Args:
            analyze_result: åˆ†æç»“æœ
            keyword: åŸå§‹æœç´¢å…³é”®è¯
            top_n: ç”Ÿæˆè¯é¢˜æ•°é‡
            images_per_topic: æ¯ä¸ªè¯é¢˜çš„å›¾ç‰‡æ•°é‡
            log_callback: æ—¥å¿—å›è°ƒ

        Returns:
            è¯é¢˜åˆ—è¡¨
        """
        if log_callback is None:
            log_callback = print

        log_callback(f"\n{'-' * 70}")
        log_callback("âœ¨ ç”Ÿæˆè¯é¢˜ï¼ˆåŸºäºäº‹å® + å…³è”é…å›¾ï¼‰")
        log_callback(f"{'-' * 70}")
        log_callback(
            f"ğŸ“Š æ•°é‡: {top_n} ä¸ª | å…³é”®è¯: {keyword} | "
            f"æ¯è¯é¢˜: {images_per_topic} å¼ å›¾"
        )
        log_callback(f"â±ï¸  é¢„è®¡: 15-45 ç§’\n")

        system_message = {"role": "system", "content": self.XHS_STYLE_PROMPT}

        user_message = {
            "role": "user",
            "content": f"""åŸºäºä»¥ä¸‹çˆ†æ¬¾å†…å®¹åˆ†ææŠ¥å‘Šå’ŒåŸå§‹ç¬”è®°æ•°æ®ï¼Œåˆ›ä½œæ–°è¯é¢˜ã€‚

## åˆ†ææŠ¥å‘Š
{json.dumps(analyze_result, ensure_ascii=False, indent=2)}

## åŸå§‹æœç´¢å…³é”®è¯
{keyword}

## âš ï¸ åå¹»è§‰è¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰

1. **è¯é¢˜å¿…é¡»åŸºäºåˆ†ææŠ¥å‘Šä¸­çš„çœŸå®è¶‹åŠ¿**ï¼Œä¸è¦å‡­ç©ºåˆ›é€ 
2. **æ­£æ–‡å†…å®¹åªèƒ½åŒ…å«ä»åˆ†ææŠ¥å‘Šä¸­èƒ½æ¨æ–­å‡ºçš„ä¿¡æ¯**ï¼Œä¸è¦ç¼–é€ å…·ä½“æ•°æ®ã€ä»£ç ç‰‡æ®µã€å¯¹æ¯”ç»“æœ
3. **å¦‚æœä½ ä¸ç¡®å®šæŸä¸ªæŠ€æœ¯ç»†èŠ‚æ˜¯å¦çœŸå®å­˜åœ¨ï¼Œå°±ä¸è¦å†™**
4. è¯é¢˜å†…å®¹åº”è¯¥æ˜¯"å¼•å¯¼æ€§+æ¡†æ¶æ€§"çš„ï¼Œè€Œä¸æ˜¯ç¼–é€ å‡çš„å…·ä½“æ•™ç¨‹
5. å¯ä»¥ç”¨"åˆ†äº«ç»éªŒ"ã€"é¿å‘æŒ‡å—"ç­‰æ¡†æ¶ï¼Œä½†ä¸è¦æé€ å…·ä½“çš„æ­¥éª¤ç»†èŠ‚

## è¯é¢˜åˆ›ä½œè¦æ±‚

è¯·ç”Ÿæˆ {top_n} ä¸ªè¯é¢˜ï¼Œæ¯ä¸ªè¯é¢˜éœ€è¦ {images_per_topic} å¼ é…å›¾ã€‚

### è¯é¢˜æ¥æº
æ¯ä¸ªè¯é¢˜å¿…é¡»æ ‡æ˜çµæ„Ÿæ¥æºäºå“ªäº›åŸå§‹ç¬”è®°ï¼ˆç”¨æ ‡é¢˜å¼•ç”¨ï¼‰ï¼Œç¡®ä¿è¯é¢˜æœ‰äº‹å®åŸºç¡€ã€‚

### è¯é¢˜å·®å¼‚åŒ–
{top_n} ä¸ªè¯é¢˜å¿…é¡»ä»ä¸åŒè§’åº¦åˆ‡å…¥ï¼š
- å¯å‚è€ƒåˆ†ææŠ¥å‘Šä¸­çš„å†…å®¹ç±»å‹åˆ†å¸ƒ
- è¦†ç›–ä¸åŒç”¨æˆ·ç¾¤ä½“ï¼ˆå°ç™½/è¿›é˜¶/ä¸“ä¸šï¼‰
- æ ‡é¢˜10-20ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œç®€æ´æœ‰åŠ›ï¼Œå«1-2ä¸ªemoji

### æ­£æ–‡è¦æ±‚
- 150-250å­—ï¼Œåˆ†æ®µè½ï¼Œå«emoji
- **åªå†™ä½ ç¡®ä¿¡çš„ä¿¡æ¯**ï¼Œç”¨å¼•å¯¼æ¡†æ¶ä»£æ›¿ç¼–é€ ç»†èŠ‚
- ä¾‹å¦‚ï¼šã€Œâœ… ç¯å¢ƒé…ç½®æœ‰å‘ï¼Œè¯„è®ºåŒºåˆ†äº«ä½ çš„è§£å†³æ–¹æ¡ˆã€è€Œä¸æ˜¯ç¼–é€ å…·ä½“é…ç½®æ­¥éª¤
- å¯ä»¥ç”¨ã€Œä½ ä»¬è§‰å¾—å‘¢ï¼Ÿã€ã€Œè¯„è®ºåŒºè®¨è®ºã€ç­‰å¼€æ”¾å¼äº’åŠ¨

### å›¾ç‰‡æç¤ºè¯è¦æ±‚ï¼ˆé€‚é…ä¸‡ç›¸2.6æ¨¡å‹ï¼‰

âš ï¸ ä¸‡ç›¸2.6æ¨¡å‹çš„èƒ½åŠ›è¾¹ç•Œï¼š
- âœ… æ“…é•¿ï¼šè‡ªç„¶åœºæ™¯ã€äººç‰©ã€ç‰©å“ã€æŠ½è±¡æ¦‚å¿µçš„è§†è§‰åŒ–ã€æ°›å›´è¥é€ 
- âŒ ä¸æ“…é•¿ï¼šæ¸²æŸ“ç²¾ç¡®æ–‡å­—ã€å¤æ‚UIç•Œé¢ã€è¯¦ç»†å›¾è¡¨ã€ä»£ç æˆªå›¾

å› æ­¤ï¼Œå›¾ç‰‡æç¤ºè¯å¿…é¡»ï¼š
1. ä½¿ç”¨è‹±æ–‡ï¼Œ30-50ä¸ªè¯ï¼ˆç®€æ´æ•ˆæœæ›´å¥½ï¼‰
2. æè¿°å…·ä½“çš„**è§†è§‰åœºæ™¯**è€ŒéæŠ½è±¡æ¦‚å¿µ
3. **ä¸è¦è¦æ±‚æ¸²æŸ“æ–‡å­—**ï¼ˆå¦‚ 'LOSS EXPLODED' è¿™ç§ï¼‰
4. **ä¸è¦æè¿°UIç•Œé¢ã€ä»£ç ç¼–è¾‘å™¨ã€è¯¦ç»†å›¾è¡¨**
5. ç”¨å…·è±¡ç‰©å“å’Œåœºæ™¯æ¥è±¡å¾æŠ½è±¡æ¦‚å¿µ
6. åŒè¯é¢˜å†…é£æ ¼ä¸€è‡´ã€å†…å®¹ä¸åŒ
7. æœ«å°¾æ·»åŠ : high quality, detailed, 4k resolution

**å¥½çš„æç¤ºè¯ç¤ºä¾‹**ï¼š
- "A cozy desk with laptop, warm coffee, scattered notes under soft morning light, minimalist style, clean composition, high quality, detailed, 4k resolution"
- "Abstract 3D geometric shapes floating in soft pastel space, representing AI technology, isometric view, C4D style, high quality, detailed, 4k resolution"

**ä¸è¦å†™è¿™ç§æç¤ºè¯**ï¼š
- "Code editor showing Python code with error message" (æ¨¡å‹æ— æ³•æ¸²æŸ“æ–‡å­—å’Œä»£ç )
- "Detailed comparison chart with performance metrics" (æ¨¡å‹æ— æ³•ç”»ç²¾ç¡®å›¾è¡¨)

### å¯é€‰è§†è§‰é£æ ¼ï¼ˆæ¯è¯é¢˜é€‰ä¸€ç§ï¼Œä¸åŒè¯é¢˜ä¸é‡å¤ï¼‰
- 3Dæ¸²æŸ“ï¼ˆ3D rendering, soft lighting, isometric view, pastel colorsï¼‰
- æ‰‹ç»˜æ’ç”»ï¼ˆhand drawn illustration, soft watercolor, warm tonesï¼‰
- æç®€æ‘„å½±ï¼ˆminimalist photography, clean negative space, natural lightï¼‰
- æ‰å¹³æ’ç”»ï¼ˆflat illustration, geometric shapes, bold colorsï¼‰
- æ°›å›´æ„Ÿæ‘„å½±ï¼ˆmoody photography, warm lighting, bokeh, lifestyleï¼‰
- ç§‘æŠ€æ„Ÿï¼ˆfuturistic, glowing elements, dark background, blue tonesï¼‰

## è¾“å‡ºæ ¼å¼

```json
[
  {{
    "title": "æ ‡é¢˜ï¼ˆ10-20å­—å«emojiï¼‰",
    "content": "æ­£æ–‡ï¼ˆ150-250å­—ï¼ŒåŸºäºäº‹å®ï¼‰",
    "tags": "#æ ‡ç­¾1 #æ ‡ç­¾2 #æ ‡ç­¾3 #æ ‡ç­¾4 #æ ‡ç­¾5",
    "source_notes": ["çµæ„Ÿæ¥æºçš„åŸå§‹ç¬”è®°æ ‡é¢˜1", "æ ‡é¢˜2"],
    "visual_style": "è§†è§‰é£æ ¼åç§°",
    "color_palette": "è‰²è°ƒæè¿°",
    "image_prompts": [
      "ç®€æ´è‹±æ–‡æç¤ºè¯, 30-50 words, high quality, detailed, 4k resolution",
      "ç®€æ´è‹±æ–‡æç¤ºè¯, 30-50 words, high quality, detailed, 4k resolution"
    ]
  }}
]
```

**ç»å¯¹çº¦æŸ**ï¼š
- image_prompts æ•°ç»„é•¿åº¦å¿…é¡»æ˜¯ {images_per_topic}
- å›¾ç‰‡æç¤ºè¯å¿…é¡»ç®€æ´ï¼ˆ30-50è¯ï¼‰ï¼Œä¸å«æ–‡å­—æ¸²æŸ“è¦æ±‚
- æ¯ä¸ªè¯é¢˜å¿…é¡»æœ‰ source_notes å­—æ®µå¼•ç”¨åŸå§‹ç¬”è®°
- ä¸åŒè¯é¢˜ä½¿ç”¨ä¸åŒè§†è§‰é£æ ¼

åªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚""",
        }

        try:
            task_enable_thinking = (
                self.enable_thinking if self.enable_thinking is not None else True
            )
            response_text = self._call_api(
                [system_message, user_message],
                temperature=0.6,
                enable_thinking=task_enable_thinking,
                log_callback=log_callback,
            )

            response_text = (
                response_text.replace("```json", "").replace("```", "").strip()
            )

            topics = json.loads(response_text)

            # éªŒè¯è¯é¢˜æ ¼å¼
            for i, topic in enumerate(topics):
                # å¿…é¡»å­—æ®µ
                for field in ["title", "content", "tags"]:
                    if field not in topic:
                        topic[field] = ""

                # å¤„ç†å›¾ç‰‡æç¤ºè¯æ ¼å¼
                if "image_prompts" not in topic or not isinstance(
                    topic["image_prompts"], list
                ):
                    # å…¼å®¹æ—§æ ¼å¼ï¼šå°†å•ä¸ª image_prompt è½¬ä¸ºåˆ—è¡¨
                    single_prompt = topic.get("image_prompt", "")
                    if single_prompt:
                        topic["image_prompts"] = [single_prompt] * images_per_topic
                    else:
                        topic["image_prompts"] = []

                # å…ƒæ•°æ®å­—æ®µ
                if "visual_style" not in topic:
                    topic["visual_style"] = "æœªæ ‡æ³¨"
                if "color_palette" not in topic:
                    topic["color_palette"] = "æœªæ ‡æ³¨"
                if "source_notes" not in topic:
                    topic["source_notes"] = []

                # åŒæ—¶ä¿ç•™ image_promptï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
                if topic["image_prompts"]:
                    topic["image_prompt"] = topic["image_prompts"][0]

            log_callback(f"\nâœ… æˆåŠŸç”Ÿæˆ {len(topics)} ä¸ªè¯é¢˜")

            # æ‰“å°è¯é¢˜é¢„è§ˆ
            log_callback(f"\nğŸ“‹ è¯é¢˜é¢„è§ˆ:")
            for i, topic in enumerate(topics[:5]):
                title = topic.get("title", "æ— æ ‡é¢˜")
                style = topic.get("visual_style", "?")
                n_prompts = len(topic.get("image_prompts", []))
                sources = topic.get("source_notes", [])
                source_str = f" â† {sources[0][:20]}..." if sources else ""
                log_callback(
                    f"   {i + 1}. {title[:35]} "
                    f"[{style}] ({n_prompts}å¼ å›¾){source_str}"
                )
            if len(topics) > 5:
                log_callback(f"   ... è¿˜æœ‰ {len(topics) - 5} ä¸ªè¯é¢˜")

            return topics

        except Exception as e:
            log_callback(f"âŒ è¯é¢˜ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def enhance_image_prompts(
        self,
        topics: List[Dict],
        log_callback: Optional[Callable] = None,
    ) -> List[Dict]:
        """
        è¿›ä¸€æ­¥ä¼˜åŒ–å›¾ç‰‡æç¤ºè¯ï¼ˆæ”¯æŒæ–°çš„ image_prompts åˆ—è¡¨æ ¼å¼ï¼‰

        Args:
            topics: è¯é¢˜åˆ—è¡¨
            log_callback: æ—¥å¿—å›è°ƒ

        Returns:
            ä¼˜åŒ–åçš„è¯é¢˜åˆ—è¡¨
        """
        if log_callback is None:
            log_callback = print

        total_prompts = sum(
            len(t.get("image_prompts", []) or [t.get("image_prompt", "")])
            for t in topics
        )
        log_callback(f"ğŸ¨ æ­£åœ¨ä¼˜åŒ– {total_prompts} ä¸ªå›¾ç‰‡æç¤ºè¯...")

        enhanced_count = 0

        for i, topic in enumerate(topics):
            prompts = topic.get("image_prompts", [])
            if not prompts:
                # å…¼å®¹æ—§æ ¼å¼
                single = topic.get("image_prompt", "")
                if single:
                    prompts = [single]
                else:
                    continue

            visual_style = topic.get("visual_style", "mixed style")
            color_palette = topic.get("color_palette", "vibrant colors")

            enhanced_prompts = []
            for j, prompt in enumerate(prompts):
                try:
                    system_message = {
                        "role": "system",
                        "content": (
                            "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIç»˜å›¾æç¤ºè¯å·¥ç¨‹å¸ˆï¼Œ"
                            "æ“…é•¿ä¸ºä¸‡ç›¸2.6æ¨¡å‹ä¼˜åŒ–è‹±æ–‡æç¤ºè¯ã€‚"
                        ),
                    }

                    user_message = {
                        "role": "user",
                        "content": f"""è¯·å°†ä»¥ä¸‹å›¾ç‰‡æç¤ºè¯ä¼˜åŒ–ï¼Œä½¿å…¶æ›´é€‚åˆä¸‡ç›¸2.6æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡å›¾ç‰‡ï¼š

åŸå§‹æç¤ºè¯ï¼š{prompt}
è§†è§‰é£æ ¼ï¼š{visual_style}
è‰²è°ƒï¼š{color_palette}
å›¾ç‰‡åºå·ï¼šç¬¬{j + 1}å¼ ï¼ˆå…±{len(prompts)}å¼ ï¼Œéœ€ä¿æŒé£æ ¼ä¸€è‡´ï¼‰

ä¼˜åŒ–è¦æ±‚ï¼š
1. ä½¿ç”¨è‹±æ–‡ï¼Œ60-80ä¸ªè¯
2. ä¿æŒä¸åŒç³»åˆ—å…¶ä»–å›¾ç‰‡ä¸€è‡´çš„è§†è§‰é£æ ¼å’Œè‰²è°ƒ
3. ä½¿ç”¨å…·ä½“çš„è§†è§‰æè¿°è¯æ±‡
4. é€‚åˆå°çº¢ä¹¦å¹³å°çš„å®¡ç¾
5. æœ«å°¾åŒ…å«: high quality, detailed, 4k resolution

ç›´æ¥è¿”å›ä¼˜åŒ–åçš„è‹±æ–‡æç¤ºè¯ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚""",
                    }

                    enhanced = self._call_api(
                        [system_message, user_message],
                        temperature=0.5,
                        enable_thinking=False,
                        log_callback=log_callback,
                    )
                    enhanced = enhanced.strip().strip('"').strip("'")
                    enhanced_prompts.append(enhanced)
                    enhanced_count += 1

                except Exception as e:
                    log_callback(f"  âš ï¸ è¯é¢˜{i + 1}å›¾{j + 1} ä¼˜åŒ–å¤±è´¥: {e}")
                    enhanced_prompts.append(prompt)  # ä¿ç•™åŸå§‹ç‰ˆæœ¬

            # ä¿å­˜åŸå§‹å’Œä¼˜åŒ–åçš„æç¤ºè¯
            topic["image_prompts_original"] = prompts
            topic["image_prompts"] = enhanced_prompts
            if enhanced_prompts:
                topic["image_prompt"] = enhanced_prompts[0]

            log_callback(
                f"  âœ… è¯é¢˜ {i + 1} æç¤ºè¯å·²ä¼˜åŒ–"
                f" ({len(enhanced_prompts)}/{len(prompts)})"
            )

        log_callback(f"âœ… æˆåŠŸä¼˜åŒ– {enhanced_count}/{total_prompts} ä¸ªæç¤ºè¯")
        return topics

    def analyze_and_create_topics(
        self,
        notes: List[Dict],
        keyword: str,
        top_n: int = 10,
        images_per_topic: int = 5,
        enhance_prompts: bool = False,
        log_callback: Optional[Callable] = None,
    ) -> Dict:
        """
        åˆ†æå¹¶ç”Ÿæˆè¯é¢˜ï¼ˆç»„åˆæ–¹æ³•ï¼‰

        Args:
            notes: ç¬”è®°åˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯
            top_n: ç”Ÿæˆè¯é¢˜æ•°é‡
            images_per_topic: æ¯ä¸ªè¯é¢˜çš„å›¾ç‰‡æ•°é‡
            enhance_prompts: æ˜¯å¦è¿›ä¸€æ­¥ä¼˜åŒ–å›¾ç‰‡æç¤ºè¯
                            ï¼ˆæ–°æ¨¡å¼ä¸‹å·²ç”Ÿæˆé«˜è´¨é‡æç¤ºè¯ï¼Œé»˜è®¤å…³é—­ï¼‰
            log_callback: æ—¥å¿—å›è°ƒ

        Returns:
            åŒ…å«åˆ†æç»“æœå’Œè¯é¢˜çš„å­—å…¸
        """
        # 1. çƒ­ç‚¹åˆ†æ
        analyze_result = self.analyze_trends(notes, top_n=50, log_callback=log_callback)

        # 2. ç”Ÿæˆè¯é¢˜ï¼ˆç»Ÿä¸€é£æ ¼ + å…³è”é…å›¾ï¼‰
        topics = self.generate_topics(
            analyze_result,
            keyword,
            top_n=top_n,
            images_per_topic=images_per_topic,
            log_callback=log_callback,
        )

        # 3. å¯é€‰ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–å›¾ç‰‡æç¤ºè¯
        # æ–°æ¨¡å¼ä¸‹ AI å·²ç”Ÿæˆé«˜è´¨é‡çš„ per-image promptsï¼Œé€šå¸¸ä¸éœ€è¦é¢å¤–ä¼˜åŒ–
        if enhance_prompts:
            topics = self.enhance_image_prompts(topics, log_callback=log_callback)

        return {"analyze_result": analyze_result, "topics": topics, "keyword": keyword}
