#!/usr/bin/env python3
"""
å°çº¢ä¹¦è‡ªåŠ¨åŒ–å·¥å…· - ä¸»ç¨‹åº
æ•´åˆæœç´¢ã€AIåˆ†æã€å›¾ç‰‡ç”Ÿæˆã€å‘å¸ƒå…¨æµç¨‹

ä½¿ç”¨æ–¹æ³•:
    python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --max-notes 50 --topics 10
"""

import argparse
import json
import os
import sys
import time
import traceback
import yaml
from datetime import datetime
from pathlib import Path
from typing import Optional
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from modules.search import XHSAdvancedSearch, DataQualityFilter
from modules.ai_engine import AIEngine
from modules.image_gen import ImageGenerator
from modules.publisher import XHSPublisher
from utils.colors import (
    C,
    colorize,
    success,
    error,
    warning,
    info,
    highlight,
    dim,
    print_banner,
    print_step,
    print_config_item,
    print_summary,
    print_progress_bar,
    emoji_status,
)
from utils.config_validator import validate_config, config_to_dict


def safe_print(text: str, end: str = "\n", flush: bool = True) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œç¡®ä¿è¾“å‡ºè¢«æ­£ç¡®æ˜¾ç¤º"""
    print(text, end=end, flush=flush)


def _verbose_log(msg: str) -> None:
    """è¯¦ç»†æ—¥å¿—å›è°ƒï¼ˆä¾›å„æ­¥éª¤ä½¿ç”¨ï¼‰"""
    safe_print(msg, flush=True)


def _save_json_file(data, file_path: Path, label: str = "æ•°æ®") -> bool:
    """
    ä¿å­˜ JSON æ•°æ®åˆ°æ–‡ä»¶ï¼Œå¹¶è¿›è¡ŒéªŒè¯

    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        file_path: æ–‡ä»¶è·¯å¾„
        label: æ•°æ®æè¿°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

    Returns:
        æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    print()
    print(f"{emoji_status('save')} æ­£åœ¨ä¿å­˜{label}...")
    print(f"   æ–‡ä»¶è·¯å¾„: {file_path}")

    try:
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        if file_path.exists():
            file_size = file_path.stat().st_size / 1024
            print(success(f"   âœ… ä¿å­˜æˆåŠŸ: {file_size:.1f} KB"))
            return True
        else:
            print(error(f"   âŒ ä¿å­˜å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨"))
            return False
    except Exception as e:
        print(error(f"   âŒ ä¿å­˜å¤±è´¥: {e}"))
        traceback.print_exc()
        return False


def print_header():
    """æ‰“å°ç¾åŒ–åçš„ç¨‹åºå¤´éƒ¨ä¿¡æ¯"""
    print_banner()
    print()
    print(colorize("ğŸ”§ åŸºäº DrissionPage + é˜¿é‡Œäº‘ç™¾ç‚¼å¤§æ¨¡å‹", C.DIM))
    print(colorize("ğŸ“– è¯¦ç»†æ–‡æ¡£: https://github.com/your-repo/xhs-automation", C.DIM))
    print()


class XHSAutomation:
    """å°çº¢ä¹¦è‡ªåŠ¨åŒ–ä¸»æ§ç±»"""

    def __init__(self, config_path: str = "config/config.yaml"):
        """
        åˆå§‹åŒ–è‡ªåŠ¨åŒ–å·¥å…·

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å– API Keyï¼Œå…¶æ¬¡ä»é…ç½®æ–‡ä»¶è¯»å–
        self.api_key = (
            os.environ.get("DASHSCOPE_API_KEY")
            or os.environ.get("ALIYUN_API_KEY")
            or self.config.get("aliyun", {}).get("api_key", "")
        )

        if not self.api_key or self.api_key == "your-dashscope-api-key-here":
            error_msg = f"""
{error("âŒ é…ç½®é”™è¯¯ï¼šç¼ºå°‘é˜¿é‡Œäº‘ç™¾ç‚¼ API Key")}

{colorize("è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€é…ç½® API Key:", C.YELLOW, C.BOLD)}

  {colorize("æ–¹æ³•1ï¼š", C.CYAN)}è®¾ç½®ç¯å¢ƒå˜é‡
     {colorize("export DASHSCOPE_API_KEY=your-api-key", C.DIM)}
     {colorize("æˆ–", C.DIM)}
     {colorize("export ALIYUN_API_KEY=your-api-key", C.DIM)}

  {colorize("æ–¹æ³•2ï¼š", C.CYAN)}ç¼–è¾‘é…ç½®æ–‡ä»¶
     {colorize("config/config.yaml", C.DIM)} â†’ å¡«å†™ aliyun.api_key

  {colorize("æ–¹æ³•3ï¼š", C.CYAN)}åˆ›å»º .env æ–‡ä»¶
     {colorize("DASHSCOPE_API_KEY=your-api-key", C.DIM)}

{colorize("ğŸ’¡ è·å– API Key:", C.BRIGHT_YELLOW)} https://bailian.console.aliyun.com/
{colorize("âš ï¸  å®‰å…¨æç¤º:", C.BRIGHT_RED)} è¯·å‹¿å°†çœŸå® API Key æäº¤åˆ°ä»£ç ä»“åº“
"""
            raise ValueError(error_msg)

    def _load_config(self, path: str) -> dict:
        """åŠ è½½å¹¶æ ¡éªŒé…ç½®æ–‡ä»¶"""
        raw_config = {}
        try:
            with open(path, "r", encoding="utf-8") as f:
                raw_config = yaml.safe_load(f) or {}
                print(success(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {path}"))
        except FileNotFoundError:
            print(warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {path}"))
            print(info("   ä½¿ç”¨é»˜è®¤é…ç½®..."))
        except Exception as e:
            print(error(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}"))
            print(info("   ä½¿ç”¨é»˜è®¤é…ç½®..."))

        # Pydantic é…ç½®æ ¡éªŒ
        try:
            validated = validate_config(raw_config)
            config = config_to_dict(validated)
            print(success("âœ… é…ç½®æ ¡éªŒé€šè¿‡"))
            return config
        except Exception as e:
            print(warning(f"âš ï¸ é…ç½®æ ¡éªŒè­¦å‘Š: {e}"))
            print(info("   ä½¿ç”¨é»˜è®¤é…ç½®è¡¥å…¨ç¼ºå¤±å­—æ®µ..."))
            return self._default_config()

    def _default_config(self) -> dict:
        """é»˜è®¤é…ç½®"""
        return {
            "aliyun": {"api_key": ""},
            "search": {
                "default_sort": "time_descending",
                "default_note_type": 51,
                "max_notes": 50,
                "min_likes": 0,
            },
            "content": {
                "topic_count": 10,
                "images_per_topic": 5,
                "image_size": "768*1152",
            },
            "publish": {
                "min_interval": 120,
                "max_interval": 180,
                "manual_confirm": True,
            },
        }

    def _create_session_dir(self, keyword: str, timestamp: str) -> Path:
        """
        åˆ›å»ºä¼šè¯ç›®å½•ï¼ˆkeyword + æ—¶é—´æˆ³ï¼‰

        Args:
            keyword: å…³é”®è¯
            timestamp: æ—¶é—´æˆ³

        Returns:
            ä¼šè¯ç›®å½•è·¯å¾„
        """
        # æ¸…ç†å…³é”®è¯ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
        safe_keyword = "".join(
            c for c in keyword if c.isalnum() or c in (" ", "_", "-")
        ).strip()
        safe_keyword = safe_keyword[:20] if len(safe_keyword) > 20 else safe_keyword

        # åˆ›å»ºç›®å½•ï¼šresults/{keyword}_{timestamp}/
        session_dir = Path("results") / f"{safe_keyword}_{timestamp}"
        session_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºå­ç›®å½•
        (session_dir / "images").mkdir(exist_ok=True)
        (session_dir / "data").mkdir(exist_ok=True)

        return session_dir

    def run(
        self,
        keyword: str,
        max_notes: int = 50,
        topic_count: int = 10,
        min_likes: int = 0,
        skip_search: bool = False,
        skip_ai: bool = False,
        skip_image: bool = False,
        skip_publish: bool = False,
        notes_file: str = "",
        topics_file: str = "",
        debug: bool = False,
        auto_publish: bool = False,
        verbose: bool = False,
        ai_model: str = "qwen3-max-2026-01-23",
        enable_thinking: Optional[bool] = None,
    ):
        """
        è¿è¡Œå®Œæ•´æµç¨‹

        Args:
            keyword: æœç´¢å…³é”®è¯
            max_notes: æœ€å¤§è·å–ç¬”è®°æ•°
            topic_count: ç”Ÿæˆè¯é¢˜æ•°é‡
            min_likes: æœ€å°ç‚¹èµæ•°è¿‡æ»¤ï¼ˆ0è¡¨ç¤ºä¸è¿‡æ»¤ï¼‰
            skip_search: è·³è¿‡æœç´¢
            skip_ai: è·³è¿‡AIåˆ†æ
            skip_image: è·³è¿‡å›¾ç‰‡ç”Ÿæˆ
            skip_publish: è·³è¿‡å‘å¸ƒ
            notes_file: ä»æ–‡ä»¶åŠ è½½ç¬”è®°
            topics_file: ä»æ–‡ä»¶åŠ è½½è¯é¢˜
            debug: å¼€å¯è°ƒè¯•æ¨¡å¼
            auto_publish: è‡ªåŠ¨å‘å¸ƒï¼ˆæ— äººå·¥ç¡®è®¤ï¼Œå¯èƒ½è§¦å‘é£æ§ï¼‰
            verbose: è¯¦ç»†è¾“å‡ºæ¨¡å¼ï¼ˆæ˜¾ç¤ºå®Œæ•´çš„APIè¾“å…¥è¾“å‡ºï¼‰
            ai_model: AIæ¨¡å‹é€‰æ‹©ï¼ˆé»˜è®¤: qwen3-max-2026-01-23ï¼‰
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆé»˜è®¤è‡ªåŠ¨ï¼šå¤æ‚ä»»åŠ¡å¯ç”¨ï¼Œç®€å•ä»»åŠ¡ç¦ç”¨ï¼‰
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä½¿ç”¨é…ç½®æˆ–å‚æ•°
        max_notes = max_notes or self.config["search"].get("max_notes", 50)
        topic_count = topic_count or self.config["content"].get("topic_count", 10)
        min_likes = (
            min_likes if min_likes >= 0 else self.config["search"].get("min_likes", 0)
        )

        # åˆ›å»ºä¼šè¯ç›®å½•
        session_dir = self._create_session_dir(keyword, timestamp)
        data_dir = session_dir / "data"
        images_dir = session_dir / "images"

        # éªŒè¯ç›®å½•æ˜¯å¦åˆ›å»ºæˆåŠŸ
        if not session_dir.exists():
            print(f"âŒ æ— æ³•åˆ›å»ºä¼šè¯ç›®å½•: {session_dir}")
            return
        if not data_dir.exists():
            print(f"âŒ æ— æ³•åˆ›å»ºæ•°æ®ç›®å½•: {data_dir}")
            return
        if not images_dir.exists():
            print(f"âŒ æ— æ³•åˆ›å»ºå›¾ç‰‡ç›®å½•: {images_dir}")
            return

        # æ‰“å°é…ç½®æ‘˜è¦
        print_header()
        print_config_item("ğŸ“Œ æœç´¢å…³é”®è¯", highlight(keyword), emoji_status("target"))
        print_config_item("ğŸ“Š çˆ¬å–ç¬”è®°æ•°", f"{max_notes} æ¡", emoji_status("info"))
        print_config_item("âœ¨ ç”Ÿæˆè¯é¢˜æ•°", f"{topic_count} ä¸ª", emoji_status("sparkle"))
        print_config_item(
            "ğŸ‘ æœ€å°ç‚¹èµæ•°", f"{min_likes}ï¼ˆ0=ä¸è¿‡æ»¤ï¼‰", emoji_status("info")
        )
        print_config_item("ğŸ¤– AI æ¨¡å‹", ai_model, emoji_status("brain"))
        # æ€è€ƒæ¨¡å¼æ˜¾ç¤º
        if enable_thinking is None:
            thinking_status = "è‡ªåŠ¨ï¼ˆå¤æ‚ä»»åŠ¡å¯ç”¨ï¼‰"
        elif enable_thinking:
            thinking_status = "å¼ºåˆ¶å¼€å¯"
        else:
            thinking_status = "å¼ºåˆ¶å…³é—­"
        print_config_item(
            "ğŸ’­ æ€è€ƒæ¨¡å¼",
            thinking_status,
            emoji_status("info"),
        )
        print_config_item(
            "ğŸ”§ è°ƒè¯•æ¨¡å¼", "å¼€å¯" if debug else "å…³é—­", emoji_status("info")
        )
        print_config_item(
            "ğŸ“¢ è¯¦ç»†è¾“å‡º", "å¼€å¯" if verbose else "å…³é—­", emoji_status("info")
        )
        print_config_item(
            "ğŸ”˜ å‘å¸ƒæ¨¡å¼",
            "å…¨è‡ªåŠ¨ï¼ˆé«˜é£é™©ï¼‰" if auto_publish else "äººå·¥ç¡®è®¤ï¼ˆæ¨èï¼‰",
            emoji_status("warning") if auto_publish else emoji_status("success"),
        )
        print_config_item("ğŸ“ å·¥ä½œç›®å½•", str(session_dir), emoji_status("info"))
        print()
        print(colorize("â”€" * 70, C.DIM))
        print()

        notes = []
        ai_result = {}
        topics = []

        # ========== Step 1: é«˜çº§æœç´¢ ==========
        if not skip_search and notes_file == "":
            print_step(
                1,
                4,
                f"{emoji_status('search')} æœç´¢çƒ­é—¨ç¬”è®°",
                f"å…³é”®è¯: {highlight(keyword)} | ç›®æ ‡: {max_notes} æ¡ç¬”è®°",
            )

            with XHSAdvancedSearch() as searcher:
                notes = searcher.search_with_filter(
                    keyword=keyword,
                    sort=self.config["search"].get("default_sort", "time_descending"),
                    note_type=self.config["search"].get("default_note_type", 51),
                    max_notes=max_notes,
                    min_likes=min_likes,
                    debug=debug,
                )

            # ç²¾å“ç¬”è®°ç­›é€‰ï¼ˆåŠ æƒè¯„åˆ† + å†…å®¹å¤šæ ·æ€§ï¼‰
            if len(notes) > 20:
                print()
                print(info(f"ğŸ” ç²¾å“ç¬”è®°ç­›é€‰ï¼ˆåŠ æƒè¯„åˆ† + å¤šæ ·æ€§å»é‡ï¼‰..."))
                quality_filter = DataQualityFilter()
                notes = quality_filter.select_premium_notes(
                    notes,
                    n=min(50, len(notes)),
                    diversity_threshold=0.6,
                    log_callback=_verbose_log,
                )

            # ä¿å­˜æœç´¢ç»“æœåˆ°ä¼šè¯ç›®å½•
            if notes:
                notes_path = data_dir / "notes.json"
                print(f"   ç¬”è®°æ•°é‡: {highlight(str(len(notes)))}")
                _save_json_file(notes, notes_path, "æœç´¢ç»“æœ")

        elif notes_file != "":
            print()
            print(info(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½ç¬”è®°: {highlight(notes_file)}"))
            try:
                with open(notes_file, "r", encoding="utf-8") as f:
                    notes = json.load(f)
                print(success(f"âœ… å·²åŠ è½½ {len(notes)} æ¡ç¬”è®°"))
            except Exception as e:
                print(error(f"âŒ åŠ è½½ç¬”è®°å¤±è´¥: {e}"))
                return
        else:
            print(info("â­ï¸ è·³è¿‡æœç´¢æ­¥éª¤"))

        # åªæœ‰åœ¨éœ€è¦AIåˆ†ææ—¶æ‰æ£€æŸ¥notes
        if not skip_ai and topics_file == "":
            if not notes:
                print(error("âŒ æ²¡æœ‰å¯ç”¨çš„ç¬”è®°æ•°æ®ï¼Œé€€å‡º"))
                return

        # ========== Step 2: AI åˆ†æ ==========
        if not skip_ai and topics_file == "":
            print_step(
                2,
                4,
                f"{emoji_status('brain')} AI çƒ­ç‚¹åˆ†æ",
                f"æ¨¡å‹: {highlight(ai_model)} | ç”Ÿæˆè¯é¢˜: {topic_count} ä¸ª",
            )

            ai = AIEngine(
                api_key=self.api_key, model=ai_model, enable_thinking=enable_thinking
            )

            # éªŒè¯ API Key
            if not ai.validate_api_key(log_callback=_verbose_log):
                print(error("âŒ API Key éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®"))
                return
            print()

            if verbose:
                print()
                print(colorize("=" * 70, C.DIM))
                print(info("ğŸ“‹ è¯¦ç»†è¾“å‡ºæ¨¡å¼å·²å¼€å¯ï¼Œå°†æ˜¾ç¤ºå®Œæ•´çš„APIäº¤äº’å†…å®¹"))
                print(colorize("=" * 70, C.DIM))
                print()

            images_per_topic = self.config["content"].get("images_per_topic", 5)
            ai_result = ai.analyze_and_create_topics(
                notes=notes,
                keyword=keyword,
                top_n=topic_count,
                images_per_topic=images_per_topic,
                log_callback=_verbose_log,
            )
            topics = ai_result["topics"]

            # ä¿å­˜åˆ†æç»“æœåˆ°ä¼šè¯ç›®å½•
            ai_path = data_dir / "ai_result.json"
            _save_json_file(ai_result, ai_path, "AIåˆ†æç»“æœ")

            # æ‰“å°åˆ†ææ‘˜è¦
            print()
            print(info("ğŸ“Š åˆ†ææ‘˜è¦:"))
            analyze = ai_result["analyze_result"]
            keywords = analyze.get("top_keywords", [])[:5]
            emotions = analyze.get("emotion_points", [])[:3]
            if keywords:
                print(f"   å…³é”®è¯: {highlight(', '.join(keywords))}")
            if emotions:
                print(f"   æƒ…ç»ªç‚¹: {highlight(', '.join(emotions))}")

        elif topics_file != "":
            print()
            print(info(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½è¯é¢˜: {highlight(topics_file)}"))
            try:
                with open(topics_file, "r", encoding="utf-8") as f:
                    if topics_file.endswith(".json"):
                        data = json.load(f)
                        if "topics" in data:
                            topics = data["topics"]
                        else:
                            topics = data
                    else:
                        topics = json.load(f)
                print(success(f"âœ… å·²åŠ è½½ {len(topics)} ä¸ªè¯é¢˜"))
            except Exception as e:
                print(error(f"âŒ åŠ è½½è¯é¢˜å¤±è´¥: {e}"))
                return
        else:
            print(info("â­ï¸ è·³è¿‡AIåˆ†ææ­¥éª¤"))

        if not topics:
            print(error("âŒ æ²¡æœ‰å¯ç”¨çš„è¯é¢˜æ•°æ®ï¼Œé€€å‡º"))
            return

        # ========== Step 3: æ–‡ç”Ÿå›¾ ==========
        if not skip_image:
            print_step(
                3,
                4,
                f"{emoji_status('image')} ç”Ÿæˆé…å›¾",
                f"æ¯ä¸ªè¯é¢˜: {self.config['content'].get('images_per_topic', 5)} å¼  | å°ºå¯¸: {self.config['content'].get('image_size', '768*1152')}",
            )

            img_gen = ImageGenerator(
                api_key=self.api_key,
                save_dir=str(images_dir),  # ä½¿ç”¨ä¼šè¯ç›®å½•ä¸‹çš„ images æ–‡ä»¶å¤¹
            )

            topics = img_gen.generate_for_topics(
                topics=topics,
                n_per_topic=self.config["content"].get("images_per_topic", 5),
                size=self.config["content"].get("image_size", "768*1152"),
                log_callback=_verbose_log,
            )

            # ä¿å­˜å¸¦å›¾ç‰‡è·¯å¾„çš„è¯é¢˜åˆ°ä¼šè¯ç›®å½•
            topics_img_path = data_dir / "topics_with_images.json"
            print(f"   è¯é¢˜æ•°é‡: {highlight(str(len(topics)))}")
            _save_json_file(topics, topics_img_path, "è¯é¢˜æ•°æ®")

        else:
            print(info("â­ï¸ è·³è¿‡å›¾ç‰‡ç”Ÿæˆæ­¥éª¤"))

        # åˆå§‹åŒ– results å˜é‡
        results = []

        # ========== Step 4: å‘å¸ƒ ==========
        if not skip_publish:
            print_step(
                4,
                4,
                f"{emoji_status('publish')} å‘å¸ƒç¬”è®°",
                f"æ¨¡å¼: {'äººå·¥ç¡®è®¤' if not auto_publish else 'å…¨è‡ªåŠ¨'} | é—´éš”: {self.config['publish'].get('min_interval', 120)}-{self.config['publish'].get('max_interval', 180)}s",
            )

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
            valid_topics = [t for t in topics if t.get("image_paths")]
            if not valid_topics:
                print(warning("âš ï¸ æ²¡æœ‰å¸¦å›¾ç‰‡çš„è¯é¢˜ï¼Œè·³è¿‡å‘å¸ƒ"))
                return

            print(info(f"ğŸ“‹ å‡†å¤‡å‘å¸ƒ {len(valid_topics)} ç¯‡ç¬”è®°\n"))

            with XHSPublisher() as publisher:
                results = publisher.publish_batch(
                    topics=valid_topics,
                    min_interval=self.config["publish"].get("min_interval", 120),
                    max_interval=self.config["publish"].get("max_interval", 180),
                    manual_confirm=not auto_publish,
                )

            # ä¿å­˜å‘å¸ƒç»“æœåˆ°ä¼šè¯ç›®å½•
            publish_result = {
                "timestamp": timestamp,
                "keyword": keyword,
                "total": len(valid_topics),
                "success": sum(results),
                "failed": len(results) - sum(results),
                "topics": [
                    {**t, "published": r} for t, r in zip(valid_topics, results)
                ],
            }
            publish_path = data_dir / "publish_result.json"
            _save_json_file(publish_result, publish_path, "å‘å¸ƒç»“æœ")

        else:
            print(info("â­ï¸ è·³è¿‡å‘å¸ƒæ­¥éª¤"))

        # æ‰“å°æ‰§è¡Œæ‘˜è¦
        results_count = {"success": 0, "failed": 0}
        if results:
            results_count["success"] = sum(results)
            results_count["failed"] = len(results) - sum(results)

        summary_data = {
            "å…³é”®è¯": keyword,
            "å·¥ä½œç›®å½•": str(session_dir),
            "çˆ¬å–ç¬”è®°": len(notes) if notes else 0,
            "ç”Ÿæˆè¯é¢˜": len(topics) if topics else 0,
            "å‘å¸ƒæˆåŠŸ": results_count["success"],
            "å‘å¸ƒå¤±è´¥": results_count["failed"],
        }
        print_summary(summary_data, "æ‰§è¡Œå®Œæˆ")
        print(
            success(f"ğŸ‰ æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {highlight(str(session_dir))}")
        )
        print()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å°çº¢ä¹¦è‡ªåŠ¨åŒ–å·¥å…· - æœç´¢â†’åˆ†æâ†’ç”Ÿæˆâ†’å‘å¸ƒ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å®Œæ•´æµç¨‹ï¼ˆé»˜è®¤ä½¿ç”¨ qwen3-maxï¼Œè‡ªåŠ¨å¯ç”¨æ€è€ƒæ¨¡å¼ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­"

  # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹ï¼ˆé€‚åˆå¿«é€Ÿæµ‹è¯•ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --ai-model qwen-turbo

  # è‡ªå®šä¹‰çˆ¬å–æ•°é‡å’Œè¯é¢˜æ•°é‡
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --max-notes 100 --topics 15
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" -n 100 -t 15  # ç®€å†™å½¢å¼

  # å¿«é€Ÿæµ‹è¯•ï¼ˆå°‘é‡æ•°æ®ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" -n 20 -t 3

  # å¼ºåˆ¶å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆæ‰€æœ‰ä»»åŠ¡éƒ½å¯ç”¨ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --enable-thinking

  # å¼ºåˆ¶ç¦ç”¨æ€è€ƒæ¨¡å¼ï¼ˆæ‰€æœ‰ä»»åŠ¡éƒ½ä¸å¯ç”¨ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --disable-thinking

  # å…¨è‡ªåŠ¨å‘å¸ƒï¼ˆâš ï¸ é«˜é£é™©ï¼Œå¯èƒ½è§¦å‘é£æ§ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --auto-publish

  # è°ƒè¯•æ¨¡å¼ï¼ˆæŸ¥çœ‹æ•°æ®ç»“æ„ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --debug

  # è¯¦ç»†è¾“å‡ºæ¨¡å¼ï¼ˆæŸ¥çœ‹å®Œæ•´APIäº¤äº’ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --verbose

  # ä¸é™åˆ¶ç‚¹èµæ•°ï¼ˆè·å–æ›´å¤šç¬”è®°ï¼‰
  python main.py --keyword "æ˜¥æ—¥ç©¿æ­" --min-likes 0

  # ä»…æœç´¢
  python main.py --keyword "ç¾å¦†" --skip-ai --skip-image --skip-publish

  # ä»å·²æœ‰å†…å®¹ç›´æ¥å‘å¸ƒ
  python main.py --keyword "é©¬å¹´æ˜¥èŠ‚" --skip-search --skip-ai --topics-file results/é©¬å¹´æ˜¥èŠ‚_xxx/data/topics_with_images.json

  # æŸ¥çœ‹å¸®åŠ©
  python main.py --help

æ€è€ƒæ¨¡å¼è¯´æ˜:
  â€¢ é»˜è®¤è‡ªåŠ¨æ¨¡å¼ï¼šå¤æ‚ä»»åŠ¡ï¼ˆçƒ­ç‚¹åˆ†æã€è¯é¢˜ç”Ÿæˆï¼‰å¯ç”¨æ€è€ƒæ¨¡å¼
  â€¢ ç®€å•ä»»åŠ¡ï¼ˆæç¤ºè¯ä¼˜åŒ–ï¼‰ä¸å¯ç”¨æ€è€ƒæ¨¡å¼ä»¥æé«˜é€Ÿåº¦
  â€¢ ä½¿ç”¨ --enable-thinking å¼ºåˆ¶æ‰€æœ‰ä»»åŠ¡å¯ç”¨æ€è€ƒæ¨¡å¼
  â€¢ ä½¿ç”¨ --disable-thinking å¼ºåˆ¶æ‰€æœ‰ä»»åŠ¡ç¦ç”¨æ€è€ƒæ¨¡å¼
        """,
    )

    parser.add_argument("--keyword", "-k", required=True, help="æœç´¢å…³é”®è¯")
    parser.add_argument(
        "--max-notes",
        "-n",
        type=int,
        default=50,
        help="çˆ¬å–ç¬”è®°æ•°é‡ (é»˜è®¤: 50ï¼Œå»ºè®® 20-100)",
    )
    parser.add_argument(
        "--topics",
        "-t",
        type=int,
        default=10,
        help="AI æ™ºèƒ½æå–çš„è¯é¢˜æ•°é‡ (é»˜è®¤: 10ï¼Œå»ºè®® 5-20)",
    )
    parser.add_argument(
        "--min-likes",
        "-l",
        type=int,
        default=0,
        help="æœ€å°ç‚¹èµæ•°è¿‡æ»¤ï¼Œ0è¡¨ç¤ºä¸è¿‡æ»¤ (é»˜è®¤: 0)",
    )
    parser.add_argument(
        "--config", "-c", default="config/config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--debug", "-d", action="store_true", help="å¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œè¾“å‡ºè¯¦ç»†æ•°æ®ç»“æ„"
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="è¯¦ç»†è¾“å‡ºæ¨¡å¼ï¼Œæ˜¾ç¤ºå®Œæ•´çš„APIè¾“å…¥è¾“å‡ºå†…å®¹",
    )

    parser.add_argument(
        "--ai-model",
        default="qwen3-max-2026-01-23",
        choices=["qwen-plus", "qwen-max", "qwen-turbo", "qwen3-max-2026-01-23"],
        help="AIæ¨¡å‹é€‰æ‹© (é»˜è®¤: qwen3-max-2026-01-23ï¼Œæœ€å¼ºæ€§èƒ½)",
    )
    parser.add_argument(
        "--enable-thinking",
        action="store_true",
        default=None,
        help="å¼ºåˆ¶å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆä»…æ”¯æŒqwen3ç³»åˆ—ï¼Œä¼šæ˜¾è‘—å¢åŠ å“åº”æ—¶é—´ï¼‰",
    )
    parser.add_argument(
        "--disable-thinking",
        action="store_true",
        help="å¼ºåˆ¶ç¦ç”¨æ€è€ƒæ¨¡å¼ï¼ˆæ‰€æœ‰ä»»åŠ¡éƒ½ä¸ä½¿ç”¨æ€è€ƒæ¨¡å¼ï¼‰",
    )

    parser.add_argument("--skip-search", action="store_true", help="è·³è¿‡æœç´¢æ­¥éª¤")
    parser.add_argument("--skip-ai", action="store_true", help="è·³è¿‡AIåˆ†ææ­¥éª¤")
    parser.add_argument("--skip-image", action="store_true", help="è·³è¿‡å›¾ç‰‡ç”Ÿæˆæ­¥éª¤")
    parser.add_argument("--skip-publish", action="store_true", help="è·³è¿‡å‘å¸ƒæ­¥éª¤")

    parser.add_argument("--notes-file", help="ä»JSONæ–‡ä»¶åŠ è½½ç¬”è®°æ•°æ®")
    parser.add_argument("--topics-file", help="ä»JSONæ–‡ä»¶åŠ è½½è¯é¢˜æ•°æ®")
    parser.add_argument(
        "--auto-publish",
        action="store_true",
        help="è‡ªåŠ¨å‘å¸ƒï¼ˆæ— äººå·¥ç¡®è®¤ï¼Œâš ï¸é«˜é£é™©ï¼šå¯èƒ½è§¦å‘å¹³å°é£æ§ï¼‰",
    )

    args = parser.parse_args()

    # å¤„ç†æ€è€ƒæ¨¡å¼å‚æ•°
    # None = è‡ªåŠ¨æ¨¡å¼ï¼ˆå¤æ‚ä»»åŠ¡å¯ç”¨ï¼Œç®€å•ä»»åŠ¡ç¦ç”¨ï¼‰
    # True = å¼ºåˆ¶å¯ç”¨
    # False = å¼ºåˆ¶ç¦ç”¨
    if args.disable_thinking:
        enable_thinking = False
    elif args.enable_thinking:
        enable_thinking = True
    else:
        enable_thinking = None  # è‡ªåŠ¨æ¨¡å¼

    try:
        app = XHSAutomation(config_path=args.config)
        app.run(
            keyword=args.keyword,
            max_notes=args.max_notes,
            topic_count=args.topics,
            min_likes=args.min_likes,
            skip_search=args.skip_search,
            skip_ai=args.skip_ai,
            skip_image=args.skip_image,
            skip_publish=args.skip_publish,
            notes_file=args.notes_file or "",
            topics_file=args.topics_file or "",
            debug=args.debug,
            auto_publish=args.auto_publish,
            verbose=args.verbose,
            ai_model=args.ai_model,
            enable_thinking=enable_thinking,
        )
    except KeyboardInterrupt:
        print()
        print()
        print(warning("âš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ"))
        print(info("   æ‚¨å¯ä»¥éšæ—¶é‡æ–°è¿è¡Œç¨‹åºç»§ç»­"))
        sys.exit(1)
    except ValueError as e:
        # é…ç½®é”™è¯¯ï¼ˆå¦‚ç¼ºå°‘API Keyï¼‰
        print()
        print()
        print(str(e))
        sys.exit(1)
    except Exception as e:
        print()
        print()
        print(error("âŒ æ‰§è¡Œå‡ºé”™"))
        print()
        print(colorize(f"é”™è¯¯ç±»å‹: {type(e).__name__}", C.BRIGHT_RED))
        print(colorize(f"é”™è¯¯ä¿¡æ¯: {str(e)}", C.RED))
        print()

        if args.debug if "args" in locals() else False:
            print(colorize("â”€" * 70, C.DIM))
            print(colorize("è¯¦ç»†å †æ ˆè·Ÿè¸ªï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰:", C.DIM))
            traceback.print_exc()
            print(colorize("â”€" * 70, C.DIM))
        else:
            print(dim("ğŸ’¡ æç¤º: ä½¿ç”¨ --debug å‚æ•°æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"))

        sys.exit(1)


if __name__ == "__main__":
    main()
